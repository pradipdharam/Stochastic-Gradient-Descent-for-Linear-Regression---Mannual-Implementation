{
  "cells": [
    {
      "metadata": {
        "_uuid": "bf229b89a23fe8752c62966ec3dcb77fc0c03b3d"
      },
      "cell_type": "markdown",
      "source": "## Problem Statement:\n** Implement Stochastic Gradient Descent for Linear regression MANUALLY with given SG formulas and apply it to Boston home price dataset; and then compare the results with actual Linear Regression from sklearn. This will give inner work of SGD. We can implement SGD for any algorithm once it is tried for Linear Regression.**\n"
    },
    {
      "metadata": {
        "_uuid": "16a00e4ceda3cee34557bec0e3802a31d4844abc"
      },
      "cell_type": "markdown",
      "source": "### Optimization problem without regulatization term and Derivatives or Gradient Descent. \n**Gradient is a slope. Instead of n in GD in diagram, we need to take bunch of k random points, suppose k=10, then we get SGD (Stochastic Gradient Descent)**\n**yi is actual value, wTxi is predicted value in below slope or derivative formulae.**"
    },
    {
      "metadata": {
        "_uuid": "1b56bf68883c48f7550b10037462140fcc7582a9"
      },
      "cell_type": "markdown",
      "source": "## Solution"
    },
    {
      "metadata": {
        "_uuid": "9eb460084dcac23c99858ace9ac848a062dc3b9c"
      },
      "cell_type": "markdown",
      "source": "### Importing lib's"
    },
    {
      "metadata": {
        "_uuid": "d91d11e15dc61b08d7ec21abbb8400ef0c9f2efe",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom matplotlib import pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c44afb558bb5acc36a884060d6a2552742a44c7d"
      },
      "cell_type": "markdown",
      "source": "### Funtion which gives rates or derivatives or slopes"
    },
    {
      "metadata": {
        "_uuid": "50759fa8e484d8dcbd9caf2129317fddbad0be43",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_slope(x_train, y_train, w, b, k=10):\n    term_1 = np.subtract(y_train, np.matmul(x_train, w.T)) - b\n    term_2 = -2 * x_train\n    \n    w = np.matmul(term_1 , term_2)    \n    b = np.average(-2 * term_1)\n    #print(\"Size b : \", b.size)\n    #Size of b is 10 here since 10 data points, b is intercept, 10 intercept for respective 10 data points\n    return w,b",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9fad51385daaee17ed176a367617ceba52bf84c2"
      },
      "cell_type": "markdown",
      "source": "### SGD function for linear regression"
    },
    {
      "metadata": {
        "_uuid": "a28392c210cd9ba5a3aaca59bec3bbc39374d1b1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def sgd_LR(x_train, y_train, w, b, iterations=100, rate_of_learning=0.01, k=10):\n                   \n    for iteration in range(iterations):\n        import random\n        k_row_nums = random.sample(range(len(x_train)),k)\n        #print(\"k_row_nums : \", k_row_nums)\n        w_slope,b_slope = get_slope( x_train[k_row_nums], y_train[k_row_nums], w, b, k)\n        \n        w = np.subtract(w, rate_of_learning * w_slope)\n        b = np.subtract(b, rate_of_learning * b_slope)\n        rate_of_learning -= 0.00000001\n    \n    return w,b",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "09eb2bf46581dafd4836caacdf859c99bdf475b8"
      },
      "cell_type": "markdown",
      "source": "### Get the Boston home proces data ser from sklearn"
    },
    {
      "metadata": {
        "_uuid": "e079b4acd155516200bf5e5f82698e70c5f5abb8",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.datasets import load_boston\nboston = load_boston()\n\nimport pandas as pd\nbos = pd.DataFrame(boston.data)\n#print(bos.head())\nbos['PRICE'] = boston.target\n\nX = bos.drop('PRICE', axis = 1)\nY = bos['PRICE']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fccd37d2ead72b163ed6de84a7dec666bd585326"
      },
      "cell_type": "markdown",
      "source": "### Split the daat into tran and test"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "daf67a18e0573613e1cd6a4191ee15886c1647bc"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = 5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "49103ea8749947076982c11047d5b6f2434bcc2f"
      },
      "cell_type": "markdown",
      "source": "### Scale or standardize the data points and convert them to array"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d71cfad45df126f5a049e57c2d454fd7c59d9583"
      },
      "cell_type": "code",
      "source": "scale = StandardScaler()\nscale.fit(x_train)\n\nx_train = scale.transform(x_train)\nx_test = scale.transform(x_test)\n\ny_train=np.array(y_train)\ny_test=np.array(y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8ea91de9246f501d7b911b5b0ac7092046a50d38"
      },
      "cell_type": "markdown",
      "source": "### Initialize w and b\n* **Initializing weight such that weights of all feature becomes zero**\n* **B is scalar is only one float value. But in get_slope function, we get b as array of 10 integers since k=10 i.e. 10 data points. We need to take average of these 10 values as b. This is because in \"Gradient Descent\" we have by default 1 data point and we get only 1 b value b; here, for \"Stochastic Gradient Descent\", we use batch of 10 points i.e. batch SGD, so we get 10 b values. Ideally, per plain, we need to have only one intercept as b, so we take average of array b as final b value**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e5bee33d2c90e0dfa0d568d613cd991b07a57c3"
      },
      "cell_type": "code",
      "source": "# Initializing weight such that weights of all feature becomes zero\nw = np.array( [0.0 for i in range(len(x_train[0]))] )\n# b is an intercept. Its a scalar not vector. Initializing b to zero\nb = 0.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f69e45c185c2bab6d63db67e1c37c02f11cc8f10"
      },
      "cell_type": "markdown",
      "source": "### Get w and b from manually developed SGD function"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f4024ab74790819dcbee6b2fa6b0b2f6d9dbcc45"
      },
      "cell_type": "code",
      "source": "w,b = sgd_LR(x_train, y_train, w, b, 100000, 0.001, 20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0cb758aab47d20c19cc5f54fde8920ac216be95d"
      },
      "cell_type": "markdown",
      "source": "### Predict the home prices for x_test using w and b got from manualy developed SGD function"
    },
    {
      "metadata": {
        "_uuid": "3670e4f69ba1824bf50f596bd6d45b40a3dd37f1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def y_predict(x_test, w, b):\n    return np.matmul(x_test, w.T) + b\n\ny_pred = y_predict(x_test, w, b)\ny_delta_SGD_manual = y_test - y_pred;",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bc1a6076285946cb293aa3774ec42a6222830277"
      },
      "cell_type": "markdown",
      "source": "### Plotting Predicted vs Actual home prices"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "061457e5f72bbc8c74e12beef7120aec10f39ef8"
      },
      "cell_type": "code",
      "source": "plt.scatter(y_test, y_pred)\nplt.xlabel(\"Prices: $Y_i$\")\nplt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\nplt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7f10c36d3a5c916b4bbaf5a41ddaad8d6786fa5a"
      },
      "cell_type": "markdown",
      "source": "## Linear Regression"
    },
    {
      "metadata": {
        "_uuid": "9952e89aaf645b2257875945c031e80a5febf921",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# code source:https://medium.com/@haydar_ai/learning-data-science-day-9-linear-regression-on-boston-housing-dataset-cd62a80775ef\nlm = LinearRegression()\nlm.fit(x_train, y_train)\ny_pred = lm.predict(x_test)\ny_delta_sklearn = y_test - y_pred\n\nplt.scatter(y_test, y_pred)\nplt.xlabel(\"Prices: $Y_i$\")\nplt.ylabel(\"Predicted prices: $\\hat{Y}_i$\")\nplt.title(\"Prices vs Predicted prices: $Y_i$ vs $\\hat{Y}_i$\")\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1d162f85b53659663efd06af1f0726fe30bc1c10"
      },
      "cell_type": "markdown",
      "source": "## Compare the weights of manually implemented SGD and sklearn Linear Regression"
    },
    {
      "metadata": {
        "_uuid": "0eddf7adbfc5533fb91adcf73ad64641a247d6ab",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Weights generated by manual SGD : \\n\", w)\nprint(\"Weights generated by sklearn Linear Regression : \\n\", lm.coef_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c70227e281a66203e9d496f3ebe1808f802aed89"
      },
      "cell_type": "markdown",
      "source": "## Observation:\n* **weights of manually implemented SGD and sklearn Linear Regression are almost similar**\n* **Scatter plots of predicted vs actual home prices for both manually implemented SGD and sklearn Linear Regression are almost similar**"
    },
    {
      "metadata": {
        "_uuid": "1038f9320297e5a9f4f11a1ef7dee181304fbf2c",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## Plotting PDF's for delta y for both sklearn Linear Regression and manual SGD\n* **delta y is (y_test - y_predicted)**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad216262b91c4b24d575d58baf8f3cf690d5a40e"
      },
      "cell_type": "code",
      "source": "import seaborn as sns;\nimport numpy as np;\n\nplt.subplot(1,2,1)\nsns.set_style('whitegrid')\nsns.kdeplot(np.array(y_delta_SGD_manual), bw=0.5)\nplt.title('PDF of $\\delta{y}$ (SGD Manual)')\n\nplt.subplot(1,2,2)\nsns.set_style('whitegrid')\nsns.kdeplot(np.array(y_delta_sklearn), bw=0.5)\nplt.title('PDF of $\\delta{y}$ (Linear Regression sklearn)')\n\nplt.tight_layout()\nplt.show()\nprint(\"delta y is (y_test - y_predicted)\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c278d13c4c7df969f17116101b3eeb46283cddd7"
      },
      "cell_type": "markdown",
      "source": "## Observation\n* **From above pdf, difference between actual home prices and predicted home prices by both the models is zero for most of the homes. **\n* **This means that actual home prices and predicted home prices are almost identical in each model**\n* **PDF's for both sklearn Linear Regression and manual SGD looks very similar**\n* **HENCE, MANUALLY developed SGD code or function or model works WELL**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1dfd6cdc23a21c846c29d1188499daa6ab5e273"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}